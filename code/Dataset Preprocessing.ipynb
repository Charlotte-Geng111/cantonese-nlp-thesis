{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1520b300",
   "metadata": {},
   "source": [
    "### 1. Conver .txt file to .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72bd8eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成，数据集已保存为 JSON 文件：Openrice_Cantonese.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"Openrice_Cantonese.txt\"  \n",
    "output_file = \"Openrice_Cantonese.json\"  \n",
    "\n",
    "formatted_data = []\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()  \n",
    "        if not line:  \n",
    "            continue\n",
    "        try:\n",
    "            # Separate CLASS and TEXT using \\t\\t\n",
    "            rating, review = line.split(\"\\t\\t\", 1)  \n",
    "            formatted_data.append({\"text\": review, \"label\": int(rating)})  \n",
    "        except ValueError:\n",
    "            print(f\"跳过格式错误的行: {line}\") #\"Misformed lines are skipped:\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(formatted_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"转换完成，数据集已保存为 JSON 文件：{output_file}\") #\"The conversion is complete and the dataset has been saved as a JSON file:\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715a68ee",
   "metadata": {},
   "source": [
    "### 2. Divided into training set and testing set\n",
    "#### “After stochastic shuffling, 90% of dataset is used as the training set, while the other 10% reviews are used as the testing set.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c45276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集已保存为：Openrice_train.json\n",
      "测试集已保存为：Openrice_test.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "input_file = \"Openrice_Cantonese.json\"  # 转换后的 JSON 文件路径\n",
    "train_file = \"Openrice_train.json\"  # 训练集文件路径\n",
    "test_file = \"Openrice_test.json\"  # 测试集文件路径\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# shuffle data randomly\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split training and test set at 90% and 10%\n",
    "train_size = int(0.9 * len(data))  # 90% used as training set\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "with open(train_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(test_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(test_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"训练集已保存为：{train_file}\")\n",
    "print(f\"测试集已保存为：{test_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc3c5c",
   "metadata": {},
   "source": [
    "### 3. Before Dataset preprocessing, the label is changed to have positive and negative emotions (1,2 is negative; 3,4,5 are heads)\n",
    "### 3. 在Dataset preprocessing前，先将label改为正面情绪和负面情绪两种（1，2为负面；3，4，5为正面）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a415fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已处理并保存为 Openrice_test_labeled.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def relabel_data(input_file, output_file):\n",
    "    # 读取 JSON 数据\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 重新标注 label\n",
    "    for entry in data:\n",
    "        if entry[\"label\"] in [1, 2]:\n",
    "            entry[\"label\"] = \"负面\"\n",
    "        elif entry[\"label\"] in [3, 4, 5]:\n",
    "            entry[\"label\"] = \"正面\"\n",
    "\n",
    "    # 保存修改后的数据\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"数据已处理并保存为 {output_file}\")\n",
    "\n",
    "# 执行代码\n",
    "input_file = \"Openrice_train.json\"\n",
    "output_file = \"Openrice_train_labeled.json\"\n",
    "input_file = \"Openrice_test.json\"\n",
    "output_file = \"Openrice_test_labeled.json\"\n",
    "\n",
    "relabel_data(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851add32",
   "metadata": {},
   "source": [
    "### 4. Adjust sample balance (training set only)\n",
    "#### ① First, count the number of positive and negative samples\n",
    "#### ② The number of additional positive samples is randomly removed, so that the number of positive samples and negative samples are the same\n",
    "#### Satisfies: the total number of samples is unchanged; Positive and negative sample equalization; Reduce positive samples (random sampling)\n",
    "\n",
    "### 4. 调整样本平衡 (仅针对训练集)\n",
    "#### ①先计算正面和负面的样本数量\n",
    "#### ②随机去除多出的正面样本数量，令正面样本数和负面样本数相同\n",
    "#### 满足：总样本数不变； 正负面样本均衡； 减少正面样本（随机采样） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7885dff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正面样本数量: 49485\n",
      "负面样本数量: 5964\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def count_labels(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Count positive and negative samples\n",
    "    positive_count = sum(1 for entry in data if entry[\"label\"] == \"正面\")\n",
    "    negative_count = sum(1 for entry in data if entry[\"label\"] == \"负面\")\n",
    "\n",
    "    print(f\"正面样本数量: {positive_count}\")\n",
    "    print(f\"负面样本数量: {negative_count}\")\n",
    "\n",
    "file_path = \"Openrice_train_labeled.json\"\n",
    "# file_path = \"Openrice_train_balanced2.json\"\n",
    "\n",
    "count_labels(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f94d2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 原始数据集: 正面 = 49485，负面 = 5964\n",
      "✅ 新数据集: 11928 条数据（正负平衡）\n",
      "✅ 增强数据已保存至 Openrice_train_balanced2.json！\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_file = \"Openrice_train_labeled.json\"\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# distinguish between positive and negative examples\n",
    "positive_samples = [d for d in data if d[\"label\"] == \"正面\"]  # positive\n",
    "negative_samples = [d for d in data if d[\"label\"] == \"负面\"]  # negative\n",
    "\n",
    "print(f\"原始数据集: 正面 = {len(positive_samples)}，负面 = {len(negative_samples)}\")\n",
    "\n",
    "# Adjust the sample balance: reduce the number of positive samples (random samples)\n",
    "target_size = len(negative_samples) * 2\n",
    "positive_samples = random.sample(positive_samples, target_size - len(negative_samples))\n",
    "\n",
    "final_data = positive_samples + negative_samples\n",
    "\n",
    "print(f\"新数据集: {len(final_data)} 条数据（正负平衡）\")\n",
    "\n",
    "output_file = \"Openrice_train_balanced2.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"增强数据已保存至 {output_file}！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8a577",
   "metadata": {},
   "source": [
    "### 5. Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c7151",
   "metadata": {},
   "source": [
    "#### 删除特殊字符，并删除多余的空格。\n",
    "#### 删除非粤语评论。在数据集中包含非粤语评论，例如英语或其他语言的评论，可能会干扰模型的训练。\n",
    "#### 和“评论的长度限制为250个字符”\n",
    "#### \n",
    "#### Remove special characters, and remove excess spaces.\n",
    "#### Delete non-Cantonese comments. The inclusion of non-Cantonese comments in the dataset, such as in English or other languages, may interfere with the training of the model.\n",
    "#### And \"The length of comment is limited to 250 characters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a2c26",
   "metadata": {},
   "source": [
    "#### 1. no emojis 去除表情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f02a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预处理完成，数据集已保存为：Openrice_train_cleaned_no_emojis.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# 输入和输出文件路径\n",
    "input_train_file = \"Openrice_train_balanced2.json\"\n",
    "# input_test_file = \"Openrice_test_labeled.json\" \n",
    "\n",
    "output_train_file = \"Openrice_train_cleaned_no_emojis.json\"  # 清理后的训练集文件\n",
    "# output_test_file = \"Openrice_test_cleaned_no_emojis.json\"  # 清理后的测试集文件\n",
    "\n",
    "# 定义清理函数\n",
    "def clean_text_no_emojis(text):\n",
    "    # 移除 <sssss> 或其他无效占位符\n",
    "    text = re.sub(r'<sssss>', '', text)\n",
    "    # 移除 emoji 和无效特殊字符\n",
    "    text = re.sub(r'[^\\w\\s.,!?]', '', text)\n",
    "    # 去除多余空格\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# 定义语言检测函数（过滤非粤语评论）\n",
    "def is_cantonese(text):\n",
    "    # 判断评论中英文字母比例\n",
    "    num_english = sum(1 for char in text if char.isalpha() and ord(char) < 128)\n",
    "    return num_english / len(text) < 0.5\n",
    "\n",
    "# 定义预处理函数\n",
    "def preprocess_data(input_file, output_file):\n",
    "    # 读取 JSON 数据\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 清理和过滤数据\n",
    "    cleaned_data = [\n",
    "        {\"text\": clean_text_no_emojis(item[\"text\"]), \"label\": item[\"label\"]}\n",
    "        for item in data\n",
    "        if is_cantonese(item[\"text\"]) and len(item[\"text\"]) > 5 and len(item[\"text\"]) <= 250\n",
    "    ]\n",
    "\n",
    "    # 保存清理后的数据\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cleaned_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"预处理完成，数据集已保存为：{output_file}\")\n",
    "\n",
    "# 对训练集和测试集分别进行预处理\n",
    "preprocess_data(input_train_file, output_train_file)\n",
    "# preprocess_data(input_test_file, output_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59536dfb",
   "metadata": {},
   "source": [
    "#### 2. with emojis 保留表情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33285e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\charlotte.geng\\anaconda3\\envs\\intel_nlp\\lib\\site-packages (2.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dfe3d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预处理完成，数据集已保存为：Openrice_train_cleaned_with_emojis.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "input_train_file = \"Openrice_train_balanced2.json\"\n",
    "# input_test_file = \"Openrice_test_labeled.json\" \n",
    "\n",
    "output_train_file = \"Openrice_train_cleaned_with_emojis.json\"  # Cleaned training set file\n",
    "# output_test_file = \"Openrice_test_cleaned_with_emojis.json\"  \n",
    "\n",
    "def clean_text_with_emojis(text):\n",
    "    # Remove <sssss> or other invalid placeholders\n",
    "    text = re.sub(r'<sssss>', '', text)\n",
    "    # Keep emoji, text, punctuation, and whitespace\n",
    "    text = ''.join(char for char in text if emoji.is_emoji(char) or char.isalnum() or char.isspace() or char in \".,!?\")\n",
    "    # Remove extra white space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Define language detection function (filter non-Cantonese reviews)\n",
    "def is_cantonese(text):\n",
    "    # Determine the ratio of letters in Chinese to English in a comment\n",
    "    num_english = sum(1 for char in text if char.isalpha() and ord(char) < 128)\n",
    "    return num_english / len(text) < 0.5\n",
    "\n",
    "def preprocess_data(input_file, output_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Clean and filter data\n",
    "    cleaned_data = [\n",
    "        {\"text\": clean_text_with_emojis(item[\"text\"]), \"label\": item[\"label\"]}\n",
    "        for item in data\n",
    "        if is_cantonese(item[\"text\"]) and len(item[\"text\"]) > 5 and len(item[\"text\"]) <= 250\n",
    "    ]\n",
    "\n",
    "    # save the cleaned data\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cleaned_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"预处理完成，数据集已保存为：{output_file}\")\n",
    "\n",
    "# Preprocess the training and test data separately\n",
    "preprocess_data(input_train_file, output_train_file)\n",
    "# preprocess_data(input_test_file, output_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a357bc5",
   "metadata": {},
   "source": [
    "#### The text containing emojis is further divided into two processing methods: \n",
    "#### 1. Retain the emojis themselves.  （No changes to the original code）\n",
    "#### 2. Translate emojis into text descriptions (e.g. \"😉\" into \"眨眼咁笑\")  （Additional code is required to handle emojis in the text）\n",
    "#### 对于包含表情符号的文本，进一步分为两种处理方式：\n",
    "#### 1. 保留表情符号本身。（原始代码没有改变）\n",
    "#### 2. 将表情符号翻译成文字描述(例如：将“😉”转换为\"眨眼咁笑\")（需要额外代码来处理文本中的表情符号）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ad86db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji 转粤语文本的转换完成，数据集已保存为：Openrice_train_cleaned_with_emojis_texts.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "input_train_file = \"Openrice_train_cleaned_with_emojis.json\"  \n",
    "# input_test_file = \"Openrice_test_cleaned_with_emojis.json\"  \n",
    "output_train_file = \"Openrice_train_cleaned_with_emojis_texts.json\"  \n",
    "# output_test_file = \"Openrice_test_cleaned_with_emojis_texts.json\"  \n",
    "\n",
    "# Define a dictionary of emoji to Cantonese descriptions\n",
    "emoji_to_cantonese = {\n",
    "  \"🙂\": \"微微笑\",\n",
    "  \"😊\": \"眼微笑，面紅紅\",\n",
    "  \"🤗\": \"笑住開手抱抱\",\n",
    "  \"😇\": \"戴住光環笑\",\n",
    "  \"😉\": \"眨眼咁笑\",\n",
    "  \"🙃\": \"反轉咗嘅樣\",\n",
    "  \"😀\": \"露齒大笑\",\n",
    "  \"😃\": \"大眼大笑露齒\",\n",
    "  \"😄\": \"眼笑齒露\",\n",
    "  \"😁\": \"眉飛色舞\",\n",
    "  \"😆\": \"咪埋眼齒露\",\n",
    "  \"😅\": \"咪埋眼齒露出汗\",\n",
    "  \"🤣\": \"滾地大笑到抽筋\",\n",
    "  \"😂\": \"開心到喊\",\n",
    "  \"🥲\": \"邊笑邊喊\",\n",
    "  \"🤤\": \"流晒口水\",\n",
    "  \"😌\": \"輕鬆晒\",\n",
    "  \"🤓\": \"書蟲樣\",\n",
    "  \"😎\": \"戴晒墨鏡笑\",\n",
    "  \"🤠\": \"戴住牛仔帽齒露笑\",\n",
    "  \"🥳\": \"戴派對帽撒花\",\n",
    "  \"☺️\": \"微微笑\",\n",
    "  \"🥰\": \"甜到漏\",\n",
    "  \"😍\": \"眼仔發心心\",\n",
    "  \"🤩\": \"眼仔發星星\",\n",
    "  \"😗\": \"嘟嘴錫人\",\n",
    "  \"😙\": \"咪埋眼嘟嘴錫人\",\n",
    "  \"😚\": \"閉埋眼嘟嘴錫人\",\n",
    "  \"😘\": \"飛個香吻\",\n",
    "  \"😳\": \"面紅晒\",\n",
    "  \"🥺\": \"楚楚可憐\",\n",
    "  \"😕\": \"好疑惑\",\n",
    "  \"🙁\": \"有啲唔開心\",\n",
    "  \"☹️\": \"唔開心\",\n",
    "  \"😟\": \"憂心忡忡\",\n",
    "  \"😮\": \"張開嘴巴好驚訝\",\n",
    "  \"😯\": \"眉飛色舞好驚訝\",\n",
    "  \"😦\": \"驚到沮喪晒\",\n",
    "  \"😧\": \"皺埋眉驚沮晒\",\n",
    "  \"😲\": \"嘩咁大反應\",\n",
    "  \"😨\": \"驚到震\",\n",
    "  \"😰\": \"冒冷汗\",\n",
    "  \"😥\": \"失望又鬆一口氣\",\n",
    "  \"😢\": \"喊緊\",\n",
    "  \"😱\": \"尖叫晒\",\n",
    "  \"😖\": \"好困惑\",\n",
    "  \"😣\": \"愁眉苦臉\",\n",
    "  \"😞\": \"失望透頂\",\n",
    "  \"😓\": \"流冷汗\",\n",
    "  \"😩\": \"煩到爆\",\n",
    "  \"😫\": \"煩到攰晒\",\n",
    "  \"😶\": \"無話可講\",\n",
    "  \"😐\": \"一般般\",\n",
    "  \"😑\": \"面癱樣\",\n",
    "  \"😒\": \"唔屑樣\",\n",
    "  \"😏\": \"奸笑\",\n",
    "  \"🤨\": \"單邊挑眉\",\n",
    "  \"🙄\": \"翻白眼\",\n",
    "  \"😬\": \"尷尬到爆\",\n",
    "  \"🤐\": \"拉鏈封晒嘴\",\n",
    "  \"🤥\": \"講大話\",\n",
    "  \"🤫\": \"噓，靜啲\",\n",
    "  \"🤭\": \"掩住嘴笑\",\n",
    "  \"🤔\": \"諗緊計\",\n",
    "  \"🧐\": \"戴單片眼鏡好嚴肅\",\n",
    "  \"😜\": \"眨眼伸舌頭\",\n",
    "  \"😝\": \"咪埋眼伸舌頭\",\n",
    "  \"😛\": \"伸舌頭\",\n",
    "  \"😋\": \"舔舔舌頭\",\n",
    "  \"🤪\": \"癲癲哋\",\n",
    "  \"🤑\": \"眼仔發錢錢\",\n",
    "  \"😠\": \"嬲嬲豬\",\n",
    "  \"😡\": \"紅晒面嬲爆\",\n",
    "  \"🤬\": \"嬲到爆粗\",\n",
    "  \"😤\": \"噴氣嬲\",\n",
    "  \"😈\": \"壞笑戴角\",\n",
    "  \"👿\": \"嬲到現形\",\n",
    "  \"😴\": \"瞓著咗\",\n",
    "  \"😪\": \"打瞌睡\",\n",
    "  \"😵\": \"頭暈\",\n",
    "  \"😵‍💫\": \"頭暈目眩\",\n",
    "  \"🤯\": \"腦袋爆晒炸\",\n",
    "  \"🤒\": \"發緊燒\",\n",
    "  \"🤕\": \"頭部撞傷\",\n",
    "  \"🤢\": \"作嘔\",\n",
    "  \"🤮\": \"嘔晒\",\n",
    "  \"🤧\": \"打晒乞嗤\",\n",
    "  \"🥵\": \"熱到暈\",\n",
    "  \"🥶\": \"凍到震\",\n",
    "  \"😷\": \"戴住口罩\", \n",
    "  \"😭\": \"喊\",\n",
    "  \"😔\": \"心唔舒服\",    \n",
    "  \"❤️\": \"鍾意\",\n",
    "  \"💔\": \"心痛\",    \n",
    "  \"💕\": \"好甜蜜\",    \n",
    "  \"🔥\": \"火爆\",\n",
    "  \"👍\": \"讚好\", \n",
    "  \"👌\": \"好正\",\n",
    "  \"🍴\": \"食好味\",\n",
    "  \"⭐\": \"星星\",\n",
    "  \"🐮\": \"牛肉\",\n",
    "  \"🐷\": \"豬肉\",\n",
    "  \"🐔\": \"雞肉\",\n",
    "  \"🐑\": \"羊肉\",\n",
    "  \"🐟\": \"魚\",\n",
    "  \"🦐\": \"蝦\",\n",
    "  \"🦀\": \"蟹\",\n",
    "  \"🦌\": \"鹿肉\",\n",
    "  \"🦆\": \"鴨肉\"\n",
    "}\n",
    "\n",
    "# Conversion function: Convert emojis to Cantonese descriptions\n",
    "def convert_emojis_to_cantonese(text):\n",
    "    # Replace emojis in the text with their Cantonese counterparts using a dictionary\n",
    "    for emoji_char, cantonese_word in emoji_to_cantonese.items():\n",
    "        text = text.replace(emoji_char, cantonese_word)\n",
    "    return text\n",
    "\n",
    "def preprocess_emojis_to_cantonese(input_file, output_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Convert emojis in each review\n",
    "    converted_data = [\n",
    "        {\"text\": convert_emojis_to_cantonese(item[\"text\"]), \"label\": item[\"label\"]}\n",
    "        for item in data\n",
    "    ]\n",
    "\n",
    "    # save the transformed data\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(converted_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"emoji 转粤语文本的转换完成，数据集已保存为：{output_file}\")\n",
    "\n",
    "# Convert training and test data\n",
    "preprocess_emojis_to_cantonese(input_train_file, output_train_file)\n",
    "# preprocess_emojis_to_cantonese(input_test_file, output_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb4dc8",
   "metadata": {},
   "source": [
    "### 6. Convert the data set to Alpaca format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a9e019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成，Alpaca 格式数据已保存为：Openrice_train_alpaca_with_emojis.json\n",
      "转换完成，Alpaca 格式数据已保存为：Openrice_train_alpaca_no_emojis.json\n",
      "转换完成，Alpaca 格式数据已保存为：Openrice_train_alpaca_with_emojis_texts.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_train_no_emojis = \"Openrice_train_cleaned_no_emojis.json\"\n",
    "# input_test_no_emojis = \"Openrice_test_cleaned_no_emojis.json\"\n",
    "input_train_with_emojis = \"Openrice_train_cleaned_with_emojis.json\"\n",
    "# input_test_with_emojis = \"Openrice_test_cleaned_with_emojis.json\"\n",
    "input_train_with_emojis_texts = \"Openrice_train_cleaned_with_emojis_texts.json\" \n",
    "# input_test_with_emojis_texts = \"Openrice_test_cleaned_with_emojis_texts.json\"  \n",
    "\n",
    "# Output file path (after converting to Alpaca)\n",
    "output_train_no_emojis = \"Openrice_train_alpaca_no_emojis.json\"\n",
    "# output_test_no_emojis = \"Openrice_test_alpaca_no_emojis.json\"\n",
    "output_train_with_emojis = \"Openrice_train_alpaca_with_emojis.json\"\n",
    "# output_test_with_emojis = \"Openrice_test_alpaca_with_emojis.json\"\n",
    "output_train_with_emojis_texts = \"Openrice_train_alpaca_with_emojis_texts.json\" \n",
    "# output_test_with_emojis_texts = \"Openrice_test_alpaca_with_emojis_texts.json\"\n",
    "\n",
    "def convert_to_alpaca_format(input_file, output_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    alpaca_data = [\n",
    "        {\n",
    "            \"instruction\": \"你是一个经过训练的人工智能，可以分析文本输入，并根据上下文将其分类为最合适的情感类型。你的任务是仔细评估输入并确定输入属于哪种情绪。从以下情绪中选择：1. “正面”，2.“负面”。只提供情绪的名称作为输出，不提供额外的解释。\",\n",
    "            \"input\": item[\"text\"],  # Comment text as input\n",
    "            \"output\": str(item[\"label\"])  # Emotion labels as output\n",
    "        }\n",
    "        for item in data\n",
    "    ]\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(alpaca_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"转换完成，Alpaca 格式数据已保存为：{output_file}\")\n",
    "\n",
    "convert_to_alpaca_format(input_train_with_emojis, output_train_with_emojis)\n",
    "# convert_to_alpaca_format(input_test_with_emojis, output_test_with_emojis)\n",
    "convert_to_alpaca_format(input_train_no_emojis, output_train_no_emojis)\n",
    "# convert_to_alpaca_format(input_test_no_emojis, output_test_no_emojis)\n",
    "convert_to_alpaca_format(input_train_with_emojis_texts, output_train_with_emojis_texts)\n",
    "# convert_to_alpaca_format(input_test_with_emojis_texts, output_test_with_emojis_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0799d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cb0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a978e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (intel_nlp)",
   "language": "python",
   "name": "intel_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
